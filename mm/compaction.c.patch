diff --git a/mm/compaction.c b/mm/compaction.c
index 9f8b1dd5303c..9e7de8e132e9 100644
--- a/mm/compaction.c
+++ b/mm/compaction.c
@@ -1342,7 +1342,7 @@ unsigned long try_to_compact_pages(struct zonelist *zonelist,
 		return COMPACT_SKIPPED;
 
 #ifdef CONFIG_CMA
-	if (gfpflags_to_migratetype(gfp_mask) == MIGRATE_MOVABLE)
+	if (gfp_mask & __GFP_CMA)
 		alloc_flags |= ALLOC_CMA;
 #endif
 	/* Compact each zone in the list */
@@ -1374,6 +1374,9 @@ unsigned long try_to_compact_pages(struct zonelist *zonelist,
 			 * succeeds in this zone.
 			 */
 			compaction_defer_reset(zone, order, false);
+#ifdef CONFIG_SEC_PHCOMP
+			count_vm_event(COMPACTCALLDEFER);
+#endif			
 			/*
 			 * It is possible that async compaction aborted due to
 			 * need_resched() and the watermarks were ok thanks to
@@ -1448,6 +1451,14 @@ static void __compact_pgdat(pg_data_t *pgdat, struct compact_control *cc)
 		INIT_LIST_HEAD(&cc->freepages);
 		INIT_LIST_HEAD(&cc->migratepages);
 
+		/*
+		 * When called via /proc/sys/vm/compact_memory
+		 * this makes sure we compact the whole zone regardless of
+		 * cached scanner positions.
+		 */
+		if (cc->order == -1)
+			__reset_isolation_suitable(zone);
+
 		if (cc->order == -1 || !compaction_deferred(zone, cc->order))
 			compact_zone(zone, cc);
 
@@ -1479,7 +1490,7 @@ static void compact_node(int nid)
 {
 	struct compact_control cc = {
 		.order = -1,
-		.mode = MIGRATE_SYNC,
+		.mode = MIGRATE_SYNC_LIGHT,
 		.ignore_skip_hint = true,
 	};
 
@@ -1498,6 +1509,40 @@ static void compact_nodes(void)
 		compact_node(nid);
 }
 
+#ifdef CONFIG_SEC_PHCOMP
+void call_compact_node(int nid, struct zone* zone, int order)
+{
+	int ret;
+	struct compact_control cc = {
+		.nr_freepages = 0,
+		.nr_migratepages = 0,
+		.ignore_skip_hint = true,
+		.order = order,
+		.zone = zone,
+		.mode = MIGRATE_SYNC_LIGHT,
+	};
+	INIT_LIST_HEAD(&cc.freepages);
+	INIT_LIST_HEAD(&cc.migratepages);
+	
+	ret = compact_zone(zone, &cc);
+	
+	if( zone_watermark_ok(zone, cc.order, low_wmark_pages(zone), 0, 0) )
+	{
+		if( cc.order >= zone->compact_order_failed )
+			zone->compact_order_failed = cc.order + 1;	
+	}
+	else if( ret == COMPACT_COMPLETE )
+	{
+		count_vm_event(PHCOMPCALLDEFER);
+		defer_compaction( zone, cc.order );
+	}
+
+	VM_BUG_ON(!list_empty(&cc.freepages));
+	VM_BUG_ON(!list_empty(&cc.migratepages));	
+	
+}
+#endif
+
 /* The written value is actually unused, all memory is compacted */
 int sysctl_compact_memory;
 
@@ -1505,8 +1550,16 @@ int sysctl_compact_memory;
 int sysctl_compaction_handler(struct ctl_table *table, int write,
 			void __user *buffer, size_t *length, loff_t *ppos)
 {
-	if (write)
+	if (write) {
+		pr_info("compact_memory start.(%d times so far)\n",
+			sysctl_compact_memory);
+		sysctl_compact_memory++;
 		compact_nodes();
+		pr_info("compact_memory done.(%d times so far)\n",
+			sysctl_compact_memory);
+	}
+	else
+		proc_dointvec(table, write, buffer, length, ppos);
 
 	return 0;
 }

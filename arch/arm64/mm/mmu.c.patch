diff --git a/arch/arm64/mm/mmu.c b/arch/arm64/mm/mmu.c
index 7f8ae8a21454..19ebba016b85 100644
--- a/arch/arm64/mm/mmu.c
+++ b/arch/arm64/mm/mmu.c
@@ -37,16 +37,27 @@
 #include <asm/tlb.h>
 #include <asm/memblock.h>
 #include <asm/mmu_context.h>
+#include <asm/map.h>
 
 #include "mm.h"
 
-u64 idmap_t0sz = TCR_T0SZ(VA_BITS);
+#include <linux/vmalloc.h>
 
+u64 idmap_t0sz = TCR_T0SZ(VA_BITS);
+static int iotable_on;
+#ifdef CONFIG_KNOX_KAP
+extern int boot_mode_security;
+#endif
 /*
  * Empty_zero_page is a special page that is used for zero-initialized data
  * and COW.
  */
+#ifdef CONFIG_TIMA_RKP
+__attribute__((section(".empty_zero_page"))) unsigned long __ezr[PAGE_SIZE / sizeof(unsigned long)] = { 0 };
+unsigned long *empty_zero_page = __ezr;
+#else
 unsigned long empty_zero_page[PAGE_SIZE / sizeof(unsigned long)] __page_aligned_bss;
+#endif
 EXPORT_SYMBOL(empty_zero_page);
 
 pgprot_t phys_mem_access_prot(struct file *file, unsigned long pfn,
@@ -68,6 +79,82 @@ static void __init *early_alloc(unsigned long sz)
 	return ptr;
 }
 
+#ifdef CONFIG_TIMA_RKP
+/* Extra memory needed by VMM */
+void* vmm_extra_mem = 0;
+spinlock_t ro_rkp_pages_lock = __SPIN_LOCK_UNLOCKED();
+char ro_pages_stat[RO_PAGES] = {0};
+unsigned ro_alloc_last = 0; 
+int rkp_ro_mapped = 0; 
+
+
+void *rkp_ro_alloc(void)
+{
+	unsigned long flags;
+	int i, j;
+	void * alloc_addr = NULL;
+	
+	spin_lock_irqsave(&ro_rkp_pages_lock,flags);
+	
+	for (i = 0, j = ro_alloc_last; i < (RO_PAGES) ; i++) {
+		j =  (j+1) %(RO_PAGES); 
+		if (!ro_pages_stat[j]) {
+			ro_pages_stat[j] = 1;
+			ro_alloc_last = j+1;
+			alloc_addr = (void*) ((u64)RKP_RBUF_VA +  (j << PAGE_SHIFT));
+			break;
+		}
+	}
+	spin_unlock_irqrestore(&ro_rkp_pages_lock,flags);
+	
+	return alloc_addr;
+}
+
+void rkp_ro_free(void *free_addr)
+{
+	int i;
+	unsigned long flags;
+
+	i =  ((u64)free_addr - (u64)RKP_RBUF_VA) >> PAGE_SHIFT;
+	spin_lock_irqsave(&ro_rkp_pages_lock,flags);
+	ro_pages_stat[i] = 0;
+	ro_alloc_last = i; 
+	spin_unlock_irqrestore(&ro_rkp_pages_lock,flags);
+}
+
+unsigned int is_rkp_ro_page(u64 addr)
+{
+	if( (addr >= (u64)RKP_RBUF_VA)
+		&& (addr < (u64)(RKP_RBUF_VA+ TIMA_ROBUF_SIZE)))
+		return 1;
+	else return 0;
+}
+/* we suppose the whole block remap to page table should start with block borders */
+static inline void __init block_to_pages(pmd_t *pmd, unsigned long addr,
+				  unsigned long end, unsigned long pfn)
+{
+	pte_t *old_pte;  
+	pmd_t new ; 
+	pte_t *pte = rkp_ro_alloc();	
+
+	old_pte = pte;
+
+	__pmd_populate(&new, __pa(pte), PMD_TYPE_TABLE); /* populate to temporary pmd */
+
+	pte = pte_offset_kernel(&new, addr);
+
+	do {		
+		if (iotable_on == 1)
+			set_pte(pte, pfn_pte(pfn, pgprot_iotable_init(PAGE_KERNEL_EXEC)));
+		else
+			set_pte(pte, pfn_pte(pfn, PAGE_KERNEL_EXEC));
+		pfn++;
+	} while (pte++, addr += PAGE_SIZE, addr != end);
+
+	__pmd_populate(pmd, __pa(old_pte), PMD_TYPE_TABLE);
+}
+#endif
+
 /*
  * remap a PMD into pages
  */
@@ -93,17 +180,23 @@ static void alloc_init_pte(pmd_t *pmd, unsigned long addr,
 {
 	pte_t *pte;
 
-	if (pmd_none(*pmd) || pmd_bad(*pmd)) {
+	if (pmd_none(*pmd) || pmd_sect(*pmd)) {
 		pte = alloc(PTRS_PER_PTE * sizeof(pte_t));
-		if (pmd_sect(*pmd))
+		if (pmd_sect(*pmd)) {
 			split_pmd(pmd, pte);
+		}
 		__pmd_populate(pmd, __pa(pte), PMD_TYPE_TABLE);
 		flush_tlb_all();
 	}
+	BUG_ON(pmd_bad(*pmd));
+
 
 	pte = pte_offset_kernel(pmd, addr);
 	do {
-		set_pte(pte, pfn_pte(pfn, prot));
+		if (iotable_on == 1)
+			set_pte(pte, pfn_pte(pfn, pgprot_iotable_init(PAGE_KERNEL_EXEC)));
+		else
+			set_pte(pte, pfn_pte(pfn, prot));
 		pfn++;
 	} while (pte++, addr += PAGE_SIZE, addr != end);
 }
@@ -127,12 +220,28 @@ static void alloc_init_pmd(struct mm_struct *mm, pud_t *pud,
 {
 	pmd_t *pmd;
 	unsigned long next;
+#ifdef CONFIG_TIMA_RKP
+	int rkp_do = 0;
+#endif
 
 	/*
 	 * Check for initial section mappings in the pgd/pud and remove them.
 	 */
 	if (pud_none(*pud) || pud_bad(*pud)) {
+#ifdef CONFIG_TIMA_RKP
+#ifdef CONFIG_KNOX_KAP
+		if (boot_mode_security)  rkp_do = 1;
+#else
+		rkp_do = 1;
+#endif
+		if( rkp_do ){
+			pmd = rkp_ro_alloc();
+		}else{
+			pmd = alloc(PTRS_PER_PMD * sizeof(pmd_t));
+		}
+#else	/* !CONFIG_TIMA_RKP */
 		pmd = alloc(PTRS_PER_PMD * sizeof(pmd_t));
+#endif
 		if (pud_sect(*pud)) {
 			/*
 			 * need to have the 1G of mappings continue to be
@@ -343,6 +452,10 @@ static void __init map_mem(void)
 	struct memblock_region *reg;
 	phys_addr_t limit;
 
+#ifdef CONFIG_TIMA_RKP
+	phys_addr_t mid = 0x60000000;
+	int rkp_do = 0;
+#endif
 	/*
 	 * Temporarily limit the memblock range. We need to do this as
 	 * create_mapping requires puds, pmds and ptes to be allocated from
@@ -361,8 +474,8 @@ static void __init map_mem(void)
 
 	/* map all the memory banks */
 	for_each_memblock(memory, reg) {
-		phys_addr_t start = reg->base;
-		phys_addr_t end = start + reg->size;
+		phys_addr_t  start = reg->base;
+		phys_addr_t  end = start + reg->size;
 
 		if (start >= end)
 			break;
@@ -382,9 +495,34 @@ static void __init map_mem(void)
 			memblock_set_current_limit(limit);
 		}
 #endif
+
+#ifdef CONFIG_TIMA_RKP
+#ifdef CONFIG_KNOX_KAP
+	if (boot_mode_security)  rkp_do = 1;
+#else
+	rkp_do = 1;
+#endif
+	if( rkp_do ){
+		__map_memblock(start, mid);
+		memset((void*)RKP_RBUF_VA, 0, TIMA_ROBUF_SIZE);
+		__map_memblock(mid, end);
+	}else{
 		__map_memblock(start, end);
 	}
+#else /* !CONFIG_TIMA_RKP */
+		__map_memblock(start, end);
+#endif
+	}
 
+#ifdef CONFIG_TIMA_RKP
+#ifdef CONFIG_KNOX_KAP
+	if (boot_mode_security) {
+#endif
+		vmm_extra_mem = early_alloc(0x600000);
+#ifdef CONFIG_KNOX_KAP
+	}
+#endif
+#endif
 	/* Limit no longer required. */
 	memblock_set_current_limit(MEMBLOCK_ALLOC_ANYWHERE);
 }
@@ -479,7 +617,23 @@ core_initcall(map_entry_trampoline);
  */
 void __init paging_init(void)
 {
+#ifdef CONFIG_TIMA_RKP
+	int rkp_do = 0;
+#endif
+
 	map_mem();
+#ifdef CONFIG_TIMA_RKP
+#ifdef CONFIG_KNOX_KAP
+	if (boot_mode_security)
+#endif
+		rkp_do = 1;
+	if (rkp_do)
+		empty_zero_page = rkp_ro_alloc();
+	else
+		empty_zero_page = early_alloc(PAGE_SIZE);
+
+	BUG_ON(empty_zero_page == NULL);
+#endif
 	fixup_executable();
 
 	bootmem_init();
@@ -491,6 +645,7 @@ void __init paging_init(void)
 	cpu_set_reserved_ttbr0();
 	local_flush_tlb_all();
 	cpu_set_default_tcr_t0sz();
+	set_memsize_kernel_type(MEMSIZE_KERNEL_OTHERS);
 }
 
 /*

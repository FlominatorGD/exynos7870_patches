diff --git a/drivers/dma/pl330.c b/drivers/dma/pl330.c
index 0b66965fad0f..dde98dd9f4a4 100644
--- a/drivers/dma/pl330.c
+++ b/drivers/dma/pl330.c
@@ -23,12 +23,15 @@
 #include <linux/dmaengine.h>
 #include <linux/amba/bus.h>
 #include <linux/amba/pl330.h>
+#include <linux/pm_runtime.h>
 #include <linux/scatterlist.h>
 #include <linux/of.h>
 #include <linux/of_dma.h>
 #include <linux/err.h>
 
 #include "dmaengine.h"
+#include <soc/samsung/exynos-pm.h>
+
 #define PL330_MAX_CHAN		8
 #define PL330_MAX_IRQS		32
 #define PL330_MAX_PERI		32
@@ -246,7 +249,18 @@ enum pl330_byteswap {
 #define MCODE_BUFF_PER_REQ	256
 
 /* Use this _only_ to wait on transient states */
-#define UNTIL(t, s)	while (!(_state(t) & (s))) cpu_relax();
+#define UNTIL(t, s)	do {									\
+				unsigned long timeout = jiffies + msecs_to_jiffies(5);		\
+				bool timeout_flag = true;					\
+				do { 								\
+					if (_state(t) & (s)) {					\
+						timeout_flag = false;				\
+						break;						\
+					}							\
+					cpu_relax();						\
+				} while (time_before(jiffies, timeout));			\
+				if (timeout_flag) pr_err("%s Timeout error!!!!\n", __func__);	\
+			} while (0)
 
 #ifdef PL330_DEBUG_MCGEN
 static unsigned cmd_line;
@@ -313,8 +327,8 @@ struct pl330_reqcfg {
  * There may be more than one xfer in a request.
  */
 struct pl330_xfer {
-	u32 src_addr;
-	u32 dst_addr;
+	dma_addr_t src_addr;
+	dma_addr_t dst_addr;
 	/* Size to xfer */
 	u32 bytes;
 };
@@ -375,6 +389,8 @@ struct pl330_thread {
 	unsigned lstenq;
 	/* Index of the last submitted request or -1 if the DMA is stopped */
 	int req_running;
+	void __iomem *ar_wrapper;
+	void __iomem *aw_wrapper;
 };
 
 enum pl330_dmac_state {
@@ -459,6 +475,12 @@ struct pl330_dmac {
 	unsigned mcbufsz;
 	/* ioremap'ed address of PL330 registers. */
 	void __iomem	*base;
+	/* Used the DMA wrapper */
+	bool wrapper;
+	/* Notifier block for powermode */
+	struct notifier_block lpa_nb;
+	void __iomem *inst_wrapper;
+	int 			usage_count;
 	/* Populated by the PL330 core driver during pl330_add */
 	struct pl330_config	pcfg;
 
@@ -500,6 +522,9 @@ struct dma_pl330_desc {
 
 	enum desc_status status;
 
+	int bytes_requested;
+	bool last;
+
 	/* The channel which currently holds this desc */
 	struct dma_pl330_chan *pchan;
 
@@ -508,6 +533,7 @@ struct dma_pl330_desc {
 	unsigned peri:5;
 	/* Hook to attach to DMAC's list of reqs with due callback */
 	struct list_head rqd;
+	unsigned int infiniteloop;
 };
 
 struct _xfer_spec {
@@ -515,6 +541,19 @@ struct _xfer_spec {
 	struct dma_pl330_desc *desc;
 };
 
+static inline void put_unaligned_le32(u32 val, u8 *p)
+{
+	*p++ = val;
+	*p++ = val >> 8;
+	*p++ = val >> 16;
+	*p++ = val >> 24;
+}
+
+static inline u32 get_unaligned_le32(u8 *p)
+{
+	return p[0] | p[1] << 8 | p[2] << 16 | p[3] << 24;
+}
+
 static inline bool _queue_empty(struct pl330_thread *thrd)
 {
 	return thrd->req[0].desc == NULL && thrd->req[1].desc == NULL;
@@ -569,7 +608,7 @@ static inline u32 _emit_END(unsigned dry_run, u8 buf[])
 	return SZ_DMAEND;
 }
 
-static inline u32 _emit_FLUSHP(unsigned dry_run, u8 buf[], u8 peri)
+static inline int _emit_FLUSHP(unsigned dry_run, u8 buf[], u8 peri)
 {
 	if (dry_run)
 		return SZ_DMAFLUSHP;
@@ -624,7 +663,7 @@ static inline u32 _emit_LDP(unsigned dry_run, u8 buf[],
 	return SZ_DMALDP;
 }
 
-static inline u32 _emit_LP(unsigned dry_run, u8 buf[],
+static inline int _emit_LP(unsigned dry_run, u8 buf[],
 		unsigned loop, u8 cnt)
 {
 	if (dry_run)
@@ -650,7 +689,7 @@ struct _arg_LPEND {
 	u8 bjump;
 };
 
-static inline u32 _emit_LPEND(unsigned dry_run, u8 buf[],
+static inline int _emit_LPEND(unsigned dry_run, u8 buf[],
 		const struct _arg_LPEND *arg)
 {
 	enum pl330_cond cond = arg->cond;
@@ -695,7 +734,7 @@ static inline u32 _emit_KILL(unsigned dry_run, u8 buf[])
 	return SZ_DMAKILL;
 }
 
-static inline u32 _emit_MOV(unsigned dry_run, u8 buf[],
+static inline int _emit_MOV(unsigned dry_run, u8 buf[],
 		enum dmamov_dst dst, u32 val)
 {
 	if (dry_run)
@@ -703,7 +742,8 @@ static inline u32 _emit_MOV(unsigned dry_run, u8 buf[],
 
 	buf[0] = CMD_DMAMOV;
 	buf[1] = dst;
-	*((u32 *)&buf[2]) = val;
+
+	put_unaligned_le32(val, &buf[2]);
 
 	PL330_DBGCMD_DUMP(SZ_DMAMOV, "\tDMAMOV %s 0x%x\n",
 		dst == SAR ? "SAR" : (dst == DAR ? "DAR" : "CCR"), val);
@@ -735,7 +775,7 @@ static inline u32 _emit_RMB(unsigned dry_run, u8 buf[])
 	return SZ_DMARMB;
 }
 
-static inline u32 _emit_SEV(unsigned dry_run, u8 buf[], u8 ev)
+static inline int _emit_SEV(unsigned dry_run, u8 buf[], u8 ev)
 {
 	if (dry_run)
 		return SZ_DMASEV;
@@ -881,31 +921,26 @@ static inline u32 _emit_GO(unsigned dry_run, u8 buf[],
 
 	buf[1] = chan & 0x7;
 
-	*((u32 *)&buf[2]) = addr;
+	put_unaligned_le32(addr, &buf[2]);
 
 	return SZ_DMAGO;
 }
 
-#define msecs_to_loops(t) (loops_per_jiffy / 1000 * HZ * t)
-
 /* Returns Time-Out */
 static bool _until_dmac_idle(struct pl330_thread *thrd)
 {
 	void __iomem *regs = thrd->dmac->base;
-	unsigned long loops = msecs_to_loops(5);
+	unsigned long timeout = jiffies + msecs_to_jiffies(5);
 
 	do {
 		/* Until Manager is Idle */
 		if (!(readl(regs + DBGSTATUS) & DBG_BUSY))
-			break;
+			return false;
 
 		cpu_relax();
-	} while (--loops);
-
-	if (!loops)
-		return true;
+	} while (time_before(jiffies, timeout));
 
-	return false;
+	return true;
 }
 
 static inline void _execute_DBGINSN(struct pl330_thread *thrd,
@@ -921,7 +956,7 @@ static inline void _execute_DBGINSN(struct pl330_thread *thrd,
 	}
 	writel(val, regs + DBGINST0);
 
-	val = *((u32 *)&insn[2]);
+	val = get_unaligned_le32(&insn[2]);
 	writel(val, regs + DBGINST1);
 
 	/* If timed out due to halted state-machine */
@@ -996,7 +1031,6 @@ static void _stop(struct pl330_thread *thrd)
 {
 	void __iomem *regs = thrd->dmac->base;
 	u8 insn[6] = {0, 0, 0, 0, 0, 0};
-	u32 inten = readl(regs + INTEN);
 
 	if (_state(thrd) == PL330_STATE_FAULT_COMPLETING)
 		UNTIL(thrd, PL330_STATE_FAULTING | PL330_STATE_KILLING);
@@ -1009,13 +1043,11 @@ static void _stop(struct pl330_thread *thrd)
 
 	_emit_KILL(0, insn);
 
-	_execute_DBGINSN(thrd, insn, is_manager(thrd));
+	/* Stop generating interrupts and clear pending interrupts for SEV */
+	writel(readl(regs + INTEN) & ~(1 << thrd->ev), regs + INTEN);
+	writel(1 << thrd->ev, regs + INTCLR);
 
-	/* clear the event */
-	if (inten & (1 << thrd->ev))
-		writel(1 << thrd->ev, regs + INTCLR);
-	/* Stop generating interrupts for SEV */
-	writel(inten & ~(1 << thrd->ev), regs + INTEN);
+	_execute_DBGINSN(thrd, insn, is_manager(thrd));
 }
 
 /* Start doing req 'idx' of thread 'thrd' */
@@ -1080,14 +1112,14 @@ static bool _start(struct pl330_thread *thrd)
 		UNTIL(thrd, PL330_STATE_FAULTING | PL330_STATE_KILLING);
 
 		if (_state(thrd) == PL330_STATE_KILLING)
-			UNTIL(thrd, PL330_STATE_STOPPED)
+			UNTIL(thrd, PL330_STATE_STOPPED);
 
 	case PL330_STATE_FAULTING:
 		_stop(thrd);
 
 	case PL330_STATE_KILLING:
 	case PL330_STATE_COMPLETING:
-		UNTIL(thrd, PL330_STATE_STOPPED)
+		UNTIL(thrd, PL330_STATE_STOPPED);
 
 	case PL330_STATE_STOPPED:
 		return _trigger(thrd);
@@ -1134,10 +1166,11 @@ static inline int _ldst_devtomem(unsigned dry_run, u8 buf[],
 		const struct _xfer_spec *pxs, int cyc)
 {
 	int off = 0;
+	enum pl330_cond cond = (pxs->desc->rqcfg.brst_len == 1) ? SINGLE : BURST;
 
 	while (cyc--) {
-		off += _emit_WFP(dry_run, &buf[off], SINGLE, pxs->desc->peri);
-		off += _emit_LDP(dry_run, &buf[off], SINGLE, pxs->desc->peri);
+		off += _emit_WFP(dry_run, &buf[off], cond, pxs->desc->peri);
+		off += _emit_LDP(dry_run, &buf[off], cond, pxs->desc->peri);
 		off += _emit_ST(dry_run, &buf[off], ALWAYS);
 		off += _emit_FLUSHP(dry_run, &buf[off], pxs->desc->peri);
 	}
@@ -1149,11 +1182,12 @@ static inline int _ldst_memtodev(unsigned dry_run, u8 buf[],
 		const struct _xfer_spec *pxs, int cyc)
 {
 	int off = 0;
+	enum pl330_cond cond = (pxs->desc->rqcfg.brst_len == 1) ? SINGLE : BURST;
 
 	while (cyc--) {
-		off += _emit_WFP(dry_run, &buf[off], SINGLE, pxs->desc->peri);
+		off += _emit_WFP(dry_run, &buf[off], cond, pxs->desc->peri);
 		off += _emit_LD(dry_run, &buf[off], ALWAYS);
-		off += _emit_STP(dry_run, &buf[off], SINGLE, pxs->desc->peri);
+		off += _emit_STP(dry_run, &buf[off], cond, pxs->desc->peri);
 		off += _emit_FLUSHP(dry_run, &buf[off], pxs->desc->peri);
 	}
 
@@ -1183,6 +1217,77 @@ static int _bursts(unsigned dry_run, u8 buf[],
 	return off;
 }
 
+/* Returns bytes consumed */
+static inline int _loop_infiniteloop(unsigned dry_run, u8 buf[],
+		unsigned long bursts, const struct _xfer_spec *pxs, int ev)
+{
+	int cyc, off;
+	unsigned lcnt0, lcnt1, ljmp0, ljmp1, ljmpfe;
+	struct _arg_LPEND lpend;
+
+	off = 0;
+	ljmpfe = off;
+	lcnt0 = pxs->desc->infiniteloop;
+
+	if (bursts > 256) {
+		lcnt1 = 256;
+		cyc = bursts / 256;
+	} else {
+		lcnt1 = bursts;
+		cyc = 1;
+	}
+
+	/* forever loop */
+	off += _emit_MOV(dry_run, &buf[off], SAR, pxs->desc->px.src_addr);
+	off += _emit_MOV(dry_run, &buf[off], DAR, pxs->desc->px.dst_addr);
+	if (pxs->desc->rqtype != DMA_MEM_TO_MEM)
+		off += _emit_FLUSHP(dry_run, &buf[off], pxs->desc->peri);
+
+	/* loop0 */
+	off += _emit_LP(dry_run, &buf[off], 0,  lcnt0);
+	ljmp0 = off;
+
+	/* loop1 */
+	off += _emit_LP(dry_run, &buf[off], 1, lcnt1);
+	ljmp1 = off;
+	off += _bursts(dry_run, &buf[off], pxs, cyc);
+	lpend.cond = ALWAYS;
+	lpend.forever = false;
+	lpend.loop = 1;
+	lpend.bjump = off - ljmp1;
+	off += _emit_LPEND(dry_run, &buf[off], &lpend);
+
+	/* remainder */
+	lcnt1 = bursts - (lcnt1 * cyc);
+
+	if (lcnt1) {
+		off += _emit_LP(dry_run, &buf[off], 1, lcnt1);
+		ljmp1 = off;
+		off += _bursts(dry_run, &buf[off], pxs, 1);
+		lpend.cond = ALWAYS;
+		lpend.forever = false;
+		lpend.loop = 1;
+		lpend.bjump = off - ljmp1;
+		off += _emit_LPEND(dry_run, &buf[off], &lpend);
+	}
+
+	off += _emit_SEV(dry_run, &buf[off], ev);
+
+	lpend.cond = ALWAYS;
+	lpend.forever = false;
+	lpend.loop = 0;
+	lpend.bjump = off - ljmp0;
+	off += _emit_LPEND(dry_run, &buf[off], &lpend);
+
+	lpend.cond = ALWAYS;
+	lpend.forever = true;
+	lpend.loop = 1;
+	lpend.bjump = off - ljmpfe;
+	off +=  _emit_LPEND(dry_run, &buf[off], &lpend);
+
+	return off;
+}
+
 /* Returns bytes consumed and updates bursts */
 static inline int _loop(unsigned dry_run, u8 buf[],
 		unsigned long *bursts, const struct _xfer_spec *pxs)
@@ -1262,6 +1367,20 @@ static inline int _loop(unsigned dry_run, u8 buf[],
 	return off;
 }
 
+static inline int _setup_xfer_infiniteloop(unsigned dry_run, u8 buf[],
+		const struct _xfer_spec *pxs, int ev)
+{
+	struct pl330_xfer *x = &pxs->desc->px;
+	u32 ccr = pxs->ccr;
+	unsigned long bursts = BYTE_TO_BURST(x->bytes, ccr);
+	int off = 0;
+
+	/* Setup Loop(s) */
+	off += _loop_infiniteloop(dry_run, &buf[off], bursts, pxs, ev);
+
+	return off;
+}
+
 static inline int _setup_loops(unsigned dry_run, u8 buf[],
 		const struct _xfer_spec *pxs)
 {
@@ -1318,12 +1437,18 @@ static int _setup_req(unsigned dry_run, struct pl330_thread *thrd,
 	if (x->bytes % (BRST_SIZE(pxs->ccr) * BRST_LEN(pxs->ccr)))
 		return -EINVAL;
 
-	off += _setup_xfer(dry_run, &buf[off], pxs);
+	if (!pxs->desc->infiniteloop) {
+		off += _setup_xfer(dry_run, &buf[off], pxs);
+
+		/* DMASEV peripheral/event */
+		off += _emit_SEV(dry_run, &buf[off], thrd->ev);
+		/* DMAEND */
+		off += _emit_END(dry_run, &buf[off]);
+	} else {
+		off += _setup_xfer_infiniteloop(dry_run, &buf[off],
+				pxs, thrd->ev);
+	}
 
-	/* DMASEV peripheral/event */
-	off += _emit_SEV(dry_run, &buf[off], thrd->ev);
-	/* DMAEND */
-	off += _emit_END(dry_run, &buf[off]);
 
 	return off;
 }
@@ -1374,6 +1499,7 @@ static int pl330_submit_req(struct pl330_thread *thrd,
 	unsigned idx;
 	u32 ccr;
 	int ret = 0;
+	struct device_node *np = thrd->dmac->ddma.dev->of_node;
 
 	if (pl330->state == DYING
 		|| pl330->dmac_tbd.reset_chan & (1 << thrd->id)) {
@@ -1428,6 +1554,11 @@ static int pl330_submit_req(struct pl330_thread *thrd,
 	thrd->req[idx].desc = desc;
 	_setup_req(0, thrd, idx, &xs);
 
+	if (np && pl330->wrapper) {
+		__raw_writel((xs.desc->px.src_addr >> 32) & 0xf, thrd->ar_wrapper);
+		__raw_writel((xs.desc->px.dst_addr >> 32) & 0xf, thrd->aw_wrapper);
+	}
+
 	ret = 0;
 
 xfer_exit:
@@ -1436,6 +1567,8 @@ xfer_exit:
 	return ret;
 }
 
+static void pl330_tasklet(unsigned long data);
+
 static void dma_pl330_rqcb(struct dma_pl330_desc *desc, enum pl330_op_err err)
 {
 	struct dma_pl330_chan *pch;
@@ -1447,7 +1580,7 @@ static void dma_pl330_rqcb(struct dma_pl330_desc *desc, enum pl330_op_err err)
 	pch = desc->pchan;
 
 	/* If desc aborted */
-	if (!pch)
+	if (!pch || !pch->thread)
 		return;
 
 	spin_lock_irqsave(&pch->lock, flags);
@@ -1456,7 +1589,10 @@ static void dma_pl330_rqcb(struct dma_pl330_desc *desc, enum pl330_op_err err)
 
 	spin_unlock_irqrestore(&pch->lock, flags);
 
-	tasklet_schedule(&pch->task);
+	if (desc->infiniteloop)
+		pl330_tasklet((unsigned long)pch);
+	else
+		tasklet_schedule(&pch->task);
 }
 
 static void pl330_dotask(unsigned long data)
@@ -1467,6 +1603,12 @@ static void pl330_dotask(unsigned long data)
 
 	spin_lock_irqsave(&pl330->lock, flags);
 
+	if (!pl330->usage_count) {
+		pr_info("[%s] Channel is already free!\n",__func__);
+		spin_unlock_irqrestore(&pl330->lock, flags);
+		return;
+	}
+
 	/* The DMAC itself gone nuts */
 	if (pl330->dmac_tbd.reset_dmac) {
 		pl330->state = DYING;
@@ -1530,6 +1672,12 @@ static int pl330_update(struct pl330_dmac *pl330)
 
 	spin_lock_irqsave(&pl330->lock, flags);
 
+	if (!pl330->usage_count) {
+		dev_err(pl330->ddma.dev, "%s:%d event is not exist!\n", __func__, __LINE__);
+		spin_unlock_irqrestore(&pl330->lock, flags);
+		return 0;
+	}
+
 	val = readl(regs + FSM) & 0x1;
 	if (val)
 		pl330->dmac_tbd.reset_mngr = true;
@@ -1577,6 +1725,9 @@ static int pl330_update(struct pl330_dmac *pl330)
 
 			id = pl330->events[ev];
 
+			if (id == -1)
+				continue;
+
 			thrd = &pl330->channels[id];
 
 			active = thrd->req_running;
@@ -1585,10 +1736,13 @@ static int pl330_update(struct pl330_dmac *pl330)
 
 			/* Detach the req */
 			descdone = thrd->req[active].desc;
-			thrd->req[active].desc = NULL;
 
-			/* Get going again ASAP */
-			_start(thrd);
+			if (!descdone->infiniteloop) {
+				thrd->req[active].desc = NULL;
+
+				/* Get going again ASAP */
+				_start(thrd);
+			}
 
 			/* For now, just make a list of callbacks to be done */
 			list_add_tail(&descdone->rqd, &pl330->req_done);
@@ -1665,6 +1819,7 @@ static struct pl330_thread *pl330_request_channel(struct pl330_dmac *pl330)
 				thrd->req[0].desc = NULL;
 				thrd->req[1].desc = NULL;
 				thrd->req_running = -1;
+				pl330->usage_count++;
 				break;
 			}
 		}
@@ -1683,8 +1838,10 @@ static inline void _free_event(struct pl330_thread *thrd, int ev)
 
 	/* If the event is valid and was held by the thread */
 	if (ev >= 0 && ev < pl330->pcfg.num_events
-			&& pl330->events[ev] == thrd->id)
+			&& pl330->events[ev] == thrd->id) {
 		pl330->events[ev] = -1;
+		pl330->usage_count--;
+	}
 }
 
 static void pl330_release_channel(struct pl330_thread *thrd)
@@ -1791,6 +1948,13 @@ static int dmac_alloc_threads(struct pl330_dmac *pl330)
 		thrd->dmac = pl330;
 		_reset_thread(thrd);
 		thrd->free = true;
+
+		if (pl330->ddma.dev->of_node && pl330->wrapper) {
+			thrd->ar_wrapper = of_dma_get_arwrapper_address(
+					pl330->ddma.dev->of_node, i);
+			thrd->aw_wrapper = of_dma_get_awwrapper_address(
+					pl330->ddma.dev->of_node, i);
+		}
 	}
 
 	/* MANAGER is indexed at the end */
@@ -1807,6 +1971,18 @@ static int dmac_alloc_resources(struct pl330_dmac *pl330)
 {
 	int chans = pl330->pcfg.num_chan;
 	int ret;
+	dma_addr_t addr;
+
+	if (pl330->ddma.dev->of_node) {
+		addr = of_dma_get_mcode_addr(pl330->ddma.dev->of_node);
+		if (addr) {
+			set_dma_ops(pl330->ddma.dev, &arm_exynos_dma_mcode_ops);
+			pl330->mcode_bus = addr;
+		}
+
+		if (pl330->wrapper)
+			pl330->inst_wrapper = of_dma_get_instwrapper_address(pl330->ddma.dev->of_node);
+	}
 
 	/*
 	 * Alloc MicroCode buffer for 'chans' Channel threads.
@@ -1815,6 +1991,10 @@ static int dmac_alloc_resources(struct pl330_dmac *pl330)
 	pl330->mcode_cpu = dma_alloc_coherent(pl330->ddma.dev,
 				chans * pl330->mcbufsz,
 				&pl330->mcode_bus, GFP_KERNEL);
+
+	if (pl330->inst_wrapper)
+		__raw_writel((pl330->mcode_bus >> 32) & 0xf, pl330->inst_wrapper);
+
 	if (!pl330->mcode_cpu) {
 		dev_err(pl330->ddma.dev, "%s:%d Can't allocate memory!\n",
 			__func__, __LINE__);
@@ -1879,6 +2059,7 @@ static int pl330_add(struct pl330_dmac *pl330)
 	tasklet_init(&pl330->tasks, pl330_dotask, (unsigned long) pl330);
 
 	pl330->state = INIT;
+	pl330->usage_count = 0;
 
 	return 0;
 }
@@ -1965,6 +2146,10 @@ static void pl330_tasklet(unsigned long data)
 	struct dma_pl330_desc *desc, *_dt;
 	unsigned long flags;
 
+	/* If pch and thread is empty */
+	if (!pch || !pch->thread)
+		return;
+
 	spin_lock_irqsave(&pch->lock, flags);
 
 	/* Pick up ripe tomatoes */
@@ -2050,6 +2235,10 @@ static int pl330_alloc_chan_resources(struct dma_chan *chan)
 	struct pl330_dmac *pl330 = pch->dmac;
 	unsigned long flags;
 
+#ifdef CONFIG_PM_RUNTIME
+	pm_runtime_get_sync(pl330->ddma.dev);
+#endif
+
 	spin_lock_irqsave(&pch->lock, flags);
 
 	dma_cookie_init(chan);
@@ -2153,6 +2342,10 @@ static void pl330_free_chan_resources(struct dma_chan *chan)
 		list_splice_tail_init(&pch->work_list, &pch->dmac->desc_pool);
 
 	spin_unlock_irqrestore(&pch->lock, flags);
+
+#ifdef CONFIG_PM_RUNTIME
+	pm_runtime_put_sync(pch->dmac->ddma.dev);
+#endif
 }
 
 static enum dma_status
@@ -2211,8 +2404,8 @@ static dma_cookie_t pl330_tx_submit(struct dma_async_tx_descriptor *tx)
 static inline void _init_desc(struct dma_pl330_desc *desc)
 {
 	desc->rqcfg.swap = SWAP_NO;
-	desc->rqcfg.scctl = CCTRL0;
-	desc->rqcfg.dcctl = CCTRL0;
+	desc->rqcfg.scctl = CCTRL2;
+	desc->rqcfg.dcctl = CCTRL2;
 	desc->txd.tx_submit = pl330_tx_submit;
 
 	INIT_LIST_HEAD(&desc->node);
@@ -2291,6 +2484,7 @@ static struct dma_pl330_desc *pl330_get_desc(struct dma_pl330_chan *pch)
 	desc->txd.cookie = 0;
 	async_tx_ack(&desc->txd);
 
+	desc->infiniteloop = 0;
 	desc->peri = peri_id ? pch->chan.chan_id : 0;
 	desc->rqcfg.pcfg = &pch->dmac->pcfg;
 
@@ -2361,7 +2555,7 @@ static inline int get_burst_len(struct dma_pl330_desc *desc, size_t len)
 static struct dma_async_tx_descriptor *pl330_prep_dma_cyclic(
 		struct dma_chan *chan, dma_addr_t dma_addr, size_t len,
 		size_t period_len, enum dma_transfer_direction direction,
-		unsigned long flags)
+		unsigned long flags, void *context)
 {
 	struct dma_pl330_desc *desc = NULL, *first = NULL;
 	struct dma_pl330_chan *pch = to_pchan(chan);
@@ -2369,6 +2563,7 @@ static struct dma_async_tx_descriptor *pl330_prep_dma_cyclic(
 	unsigned int i;
 	dma_addr_t dst;
 	dma_addr_t src;
+	unsigned int *infinite = context;
 
 	if (len % period_len != 0)
 		return NULL;
@@ -2423,6 +2618,7 @@ static struct dma_async_tx_descriptor *pl330_prep_dma_cyclic(
 		desc->rqtype = direction;
 		desc->rqcfg.brst_size = pch->burst_sz;
 		desc->rqcfg.brst_len = 1;
+		desc->infiniteloop = *infinite;
 		fill_px(&desc->px, dst, src, period_len);
 
 		if (!first)
@@ -2448,12 +2644,14 @@ pl330_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dst,
 {
 	struct dma_pl330_desc *desc;
 	struct dma_pl330_chan *pch = to_pchan(chan);
-	struct pl330_dmac *pl330 = pch->dmac;
+	struct pl330_dmac *pl330;
 	int burst;
 
 	if (unlikely(!pch || !len))
 		return NULL;
 
+	pl330 = pch->dmac;
+
 	desc = __pl330_prep_dma_memcpy(pch, dst, src, len);
 	if (!desc)
 		return NULL;
@@ -2485,6 +2683,7 @@ pl330_prep_dma_memcpy(struct dma_chan *chan, dma_addr_t dst,
 		desc->rqcfg.brst_len = 1;
 
 	desc->rqcfg.brst_len = get_burst_len(desc, len);
+	desc->bytes_requested = len;
 
 	desc->txd.flags = flags;
 
@@ -2563,7 +2762,7 @@ pl330_prep_slave_sg(struct dma_chan *chan, struct scatterlist *sgl,
 		}
 
 		desc->rqcfg.brst_size = pch->burst_sz;
-		desc->rqcfg.brst_len = 1;
+		desc->rqcfg.brst_len = pch->burst_len;
 		desc->rqtype = direction;
 	}
 
@@ -2580,6 +2779,28 @@ static irqreturn_t pl330_irq_handler(int irq, void *data)
 		return IRQ_NONE;
 }
 
+int pl330_dma_getposition(struct dma_chan *chan,
+		dma_addr_t *src, dma_addr_t *dst)
+{
+	struct dma_pl330_chan *pch = to_pchan(chan);
+	struct pl330_dmac *pi;
+	void __iomem *regs;
+	struct pl330_thread *thrd;
+
+	if (unlikely(!pch))
+		return -EINVAL;
+
+	thrd = pch->thread;
+	pi = pch->dmac;
+	regs = pi->base;
+
+	*src = readl(regs + SA(thrd->id));
+	*dst = readl(regs + DA(thrd->id));
+
+	return 0;
+}
+EXPORT_SYMBOL(pl330_dma_getposition);
+
 #define PL330_DMA_BUSWIDTHS \
 	BIT(DMA_SLAVE_BUSWIDTH_UNDEFINED) | \
 	BIT(DMA_SLAVE_BUSWIDTH_1_BYTE) | \
@@ -2600,6 +2821,49 @@ static int pl330_dma_device_slave_caps(struct dma_chan *dchan,
 	return 0;
 }
 
+#ifdef CONFIG_CPU_IDLE
+static int pl330_notifier(struct notifier_block *nb,
+			unsigned long event, void *data)
+{
+	struct pl330_dmac *pl330 =
+		container_of(nb, struct pl330_dmac, lpa_nb);
+
+	switch (event) {
+	case LPA_EXIT:
+		if (pl330->inst_wrapper)
+			__raw_writel((pl330->mcode_bus >> 32) & 0xf, pl330->inst_wrapper);
+		break;
+	}
+
+	return NOTIFY_OK;
+}
+#endif /* CONFIG_CPU_IDLE */
+
+#ifdef CONFIG_PM
+static int pl330_resume(struct device *dev)
+{
+	struct pl330_dmac *pl330;
+
+	pl330 = (struct pl330_dmac *)dev_get_drvdata(dev);
+
+	if (pl330->inst_wrapper)
+		__raw_writel((pl330->mcode_bus >> 32) & 0xf, pl330->inst_wrapper);
+
+	return 0;
+}
+
+static const struct dev_pm_ops pl330_pm_ops = {
+	.resume		= pl330_resume,
+};
+
+#define PL330_PM (&pl330_pm_ops)
+
+#else /* CONFIG_PM */
+
+#define PL330_PM NULL
+
+#endif /* !CONFIG_PM */
+
 static int
 pl330_probe(struct amba_device *adev, const struct amba_id *id)
 {
@@ -2625,6 +2889,7 @@ pl330_probe(struct amba_device *adev, const struct amba_id *id)
 		return -ENOMEM;
 	}
 
+	pl330->ddma.dev = &adev->dev;
 	pl330->mcbufsz = pdat ? pdat->mcbuf_sz : 0;
 
 	res = &adev->res;
@@ -2647,6 +2912,14 @@ pl330_probe(struct amba_device *adev, const struct amba_id *id)
 		}
 	}
 
+	if (adev->dev.of_node){
+		*adev->dev.dma_mask = of_dma_get_mask(adev->dev.of_node,
+				"dma-mask-bit");
+		adev->dev.coherent_dma_mask = of_dma_get_mask(adev->dev.of_node,
+				"coherent-mask-bit");
+		pl330->wrapper = of_dma_get_wrapper_available(adev->dev.of_node);
+	}
+
 	pcfg = &pl330->pcfg;
 
 	pcfg->periph_id = adev->periphid;
@@ -2753,6 +3026,22 @@ pl330_probe(struct amba_device *adev, const struct amba_id *id)
 		pcfg->data_buf_dep, pcfg->data_bus_width / 8, pcfg->num_chan,
 		pcfg->num_peri, pcfg->num_events);
 
+#ifdef CONFIG_CPU_IDLE
+	pl330->lpa_nb.notifier_call = pl330_notifier;
+	pl330->lpa_nb.next = NULL;
+	pl330->lpa_nb.priority = 0;
+
+	ret = exynos_pm_register_notifier(&pl330->lpa_nb);
+	if (ret) {
+		dev_err(&adev->dev, "failed to register pm notifier\n");
+		goto probe_err3;
+	}
+#endif
+
+#ifdef CONFIG_PM_RUNTIME
+	pm_runtime_put_sync(&adev->dev);
+#endif
+
 	return 0;
 probe_err3:
 	/* Idle the DMAC */
@@ -2816,6 +3105,7 @@ MODULE_DEVICE_TABLE(amba, pl330_ids);
 static struct amba_driver pl330_driver = {
 	.drv = {
 		.owner = THIS_MODULE,
+		.pm = PL330_PM,
 		.name = "dma-pl330",
 	},
 	.id_table = pl330_ids,

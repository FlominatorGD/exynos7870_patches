diff --git a/drivers/clocksource/exynos_mct.c b/drivers/clocksource/exynos_mct.c
index c844616028d2..d3ed0feea496 100644
--- a/drivers/clocksource/exynos_mct.c
+++ b/drivers/clocksource/exynos_mct.c
@@ -26,6 +26,10 @@
 #include <linux/clocksource.h>
 #include <linux/sched_clock.h>
 
+#ifdef CONFIG_SEC_EXT
+#include <linux/sec_ext.h>
+#endif
+
 #define EXYNOS4_MCTREG(x)		(x)
 #define EXYNOS4_MCT_G_CNT_L		EXYNOS4_MCTREG(0x100)
 #define EXYNOS4_MCT_G_CNT_U		EXYNOS4_MCTREG(0x104)
@@ -86,6 +90,8 @@ struct mct_clock_event_device {
 	struct clock_event_device evt;
 	unsigned long base;
 	char name[10];
+	struct irqaction irq;
+	bool setup_once;
 };
 
 static void exynos4_mct_write(unsigned int value, unsigned long offset)
@@ -218,6 +224,7 @@ struct clocksource mct_frc = {
 	.resume		= exynos4_frc_resume,
 };
 
+#if !IS_ENABLED(CONFIG_ARM64) && !IS_ENABLED(CONFIG_ARM_ARCH_TIMER)
 static u64 notrace exynos4_read_sched_clock(void)
 {
 	return exynos4_read_count_32();
@@ -231,19 +238,21 @@ static cycles_t exynos4_read_current_timer(void)
 			 "cycles_t needs to move to 32-bit for ARM64 usage");
 	return exynos4_read_count_32();
 }
+#endif
 
 static void __init exynos4_clocksource_init(void)
 {
 	exynos4_mct_frc_start();
 
+#if !IS_ENABLED(CONFIG_ARM64) && !IS_ENABLED(CONFIG_ARM_ARCH_TIMER)
 	exynos4_delay_timer.read_current_timer = &exynos4_read_current_timer;
 	exynos4_delay_timer.freq = clk_rate;
 	register_current_timer_delay(&exynos4_delay_timer);
-
 	if (clocksource_register_hz(&mct_frc, clk_rate))
 		panic("%s: can't register clocksource\n", mct_frc.name);
 
 	sched_clock_register(exynos4_read_sched_clock, 32, clk_rate);
+#endif
 }
 
 static void exynos4_mct_comp0_stop(void)
@@ -346,26 +355,26 @@ static void exynos4_clockevent_init(void)
 static DEFINE_PER_CPU(struct mct_clock_event_device, percpu_mct_tick);
 
 /* Clock event handling */
-static void exynos4_mct_tick_stop(struct mct_clock_event_device *mevt)
+static void exynos4_mct_tick_stop(struct mct_clock_event_device *mevt, int force)
 {
 	unsigned long tmp;
-	unsigned long mask = MCT_L_TCON_INT_START | MCT_L_TCON_TIMER_START;
-	unsigned long offset = mevt->base + MCT_L_TCON_OFFSET;
+	struct clock_event_device *evt = &mevt->evt;
+
+	/* clear MCT local interrupt */
+	exynos4_mct_write(0x1, mevt->base + MCT_L_INT_CSTAT_OFFSET);
 
-	tmp = readl_relaxed(reg_base + offset);
-	if (tmp & mask) {
-		tmp &= ~mask;
-		exynos4_mct_write(tmp, offset);
+	if (force || evt->mode != CLOCK_EVT_MODE_PERIODIC) {
+		tmp = __raw_readl(reg_base + mevt->base + MCT_L_TCON_OFFSET);
+		tmp &= ~(MCT_L_TCON_INT_START | MCT_L_TCON_TIMER_START);
+		exynos4_mct_write(tmp, mevt->base + MCT_L_TCON_OFFSET);
 	}
 }
 
-static void exynos4_mct_tick_start(unsigned long cycles,
+static void exynos4_mct_tick_start(unsigned long cycles, int periodic,
 				   struct mct_clock_event_device *mevt)
 {
 	unsigned long tmp;
 
-	exynos4_mct_tick_stop(mevt);
-
 	tmp = (1 << 31) | cycles;	/* MCT_L_UPDATE_ICNTB */
 
 	/* update interrupt count buffer */
@@ -375,8 +384,11 @@ static void exynos4_mct_tick_start(unsigned long cycles,
 	exynos4_mct_write(0x1, mevt->base + MCT_L_INT_ENB_OFFSET);
 
 	tmp = readl_relaxed(reg_base + mevt->base + MCT_L_TCON_OFFSET);
-	tmp |= MCT_L_TCON_INT_START | MCT_L_TCON_TIMER_START |
-	       MCT_L_TCON_INTERVAL_MODE;
+	tmp |= MCT_L_TCON_INT_START | MCT_L_TCON_TIMER_START;
+
+	if (periodic)
+		tmp |= MCT_L_TCON_INTERVAL_MODE;
+
 	exynos4_mct_write(tmp, mevt->base + MCT_L_TCON_OFFSET);
 }
 
@@ -385,7 +397,7 @@ static int exynos4_tick_set_next_event(unsigned long cycles,
 {
 	struct mct_clock_event_device *mevt = this_cpu_ptr(&percpu_mct_tick);
 
-	exynos4_mct_tick_start(cycles, mevt);
+	exynos4_mct_tick_start(cycles, 0, mevt);
 
 	return 0;
 }
@@ -396,50 +408,31 @@ static inline void exynos4_tick_set_mode(enum clock_event_mode mode,
 	struct mct_clock_event_device *mevt = this_cpu_ptr(&percpu_mct_tick);
 	unsigned long cycles_per_jiffy;
 
-	exynos4_mct_tick_stop(mevt);
+	exynos4_mct_tick_stop(mevt, 1);
 
 	switch (mode) {
 	case CLOCK_EVT_MODE_PERIODIC:
 		cycles_per_jiffy =
 			(((unsigned long long) NSEC_PER_SEC / HZ * evt->mult) >> evt->shift);
-		exynos4_mct_tick_start(cycles_per_jiffy, mevt);
+		exynos4_mct_tick_start(cycles_per_jiffy, 1, mevt);
+		break;
+	case CLOCK_EVT_MODE_RESUME:
+		exynos4_mct_write(TICK_BASE_CNT, mevt->base + MCT_L_TCNTB_OFFSET);
 		break;
 
 	case CLOCK_EVT_MODE_ONESHOT:
 	case CLOCK_EVT_MODE_UNUSED:
 	case CLOCK_EVT_MODE_SHUTDOWN:
-	case CLOCK_EVT_MODE_RESUME:
 		break;
 	}
 }
 
-static int exynos4_mct_tick_clear(struct mct_clock_event_device *mevt)
-{
-	struct clock_event_device *evt = &mevt->evt;
-
-	/*
-	 * This is for supporting oneshot mode.
-	 * Mct would generate interrupt periodically
-	 * without explicit stopping.
-	 */
-	if (evt->mode != CLOCK_EVT_MODE_PERIODIC)
-		exynos4_mct_tick_stop(mevt);
-
-	/* Clear the MCT tick interrupt */
-	if (readl_relaxed(reg_base + mevt->base + MCT_L_INT_CSTAT_OFFSET) & 1) {
-		exynos4_mct_write(0x1, mevt->base + MCT_L_INT_CSTAT_OFFSET);
-		return 1;
-	} else {
-		return 0;
-	}
-}
-
 static irqreturn_t exynos4_mct_tick_isr(int irq, void *dev_id)
 {
 	struct mct_clock_event_device *mevt = dev_id;
 	struct clock_event_device *evt = &mevt->evt;
 
-	exynos4_mct_tick_clear(mevt);
+	exynos4_mct_tick_stop(mevt, 0);
 
 	evt->event_handler(evt);
 
@@ -453,30 +446,43 @@ static int exynos4_local_timer_setup(struct clock_event_device *evt)
 
 	mevt = container_of(evt, struct mct_clock_event_device, evt);
 
-	mevt->base = EXYNOS4_MCT_L_BASE(cpu);
-	snprintf(mevt->name, sizeof(mevt->name), "mct_tick%d", cpu);
-
-	evt->name = mevt->name;
-	evt->cpumask = cpumask_of(cpu);
-	evt->set_next_event = exynos4_tick_set_next_event;
-	evt->set_mode = exynos4_tick_set_mode;
-	evt->features = CLOCK_EVT_FEAT_PERIODIC | CLOCK_EVT_FEAT_ONESHOT;
-	evt->rating = 450;
+	if (!mevt->setup_once) {
+		mevt->base = EXYNOS4_MCT_L_BASE(cpu);
+		snprintf(mevt->name, sizeof(mevt->name), "mct_tick%d", cpu);
+
+		evt->name = mevt->name;
+		evt->cpumask = cpumask_of(cpu);
+		evt->set_next_event = exynos4_tick_set_next_event;
+		evt->set_mode = exynos4_tick_set_mode;
+		evt->features = CLOCK_EVT_FEAT_PERIODIC | CLOCK_EVT_FEAT_ONESHOT;
+		evt->rating = 450;
+
+		if (mct_int_type == MCT_INT_SPI) {
+			/* fill irq_action structure */
+			mevt->irq.flags = IRQF_TIMER | IRQF_NOBALANCING | IRQF_PERCPU;
+			mevt->irq.handler = exynos4_mct_tick_isr;
+			mevt->irq.name = mevt->name;
+			mevt->irq.dev_id = mevt;
+			/* assign interrupt interrupt number */
+			evt->irq = mct_irqs[MCT_L0_IRQ + cpu];
+			setup_irq(mct_irqs[MCT_L0_IRQ + cpu], &mevt->irq);
+			disable_irq(mct_irqs[MCT_L0_IRQ + cpu]);
+		}
+	}
 
 	exynos4_mct_write(TICK_BASE_CNT, mevt->base + MCT_L_TCNTB_OFFSET);
 
 	if (mct_int_type == MCT_INT_SPI) {
+		irq_force_affinity(mct_irqs[MCT_L0_IRQ + cpu], cpumask_of(cpu));
 
-		if (evt->irq == -1)
-			return -EIO;
-
-		irq_force_affinity(evt->irq, cpumask_of(cpu));
 		enable_irq(evt->irq);
 	} else {
 		enable_percpu_irq(mct_irqs[MCT_L0_IRQ], 0);
 	}
 	clockevents_config_and_register(evt, clk_rate / (TICK_BASE_CNT + 1),
 					0xf, 0x7fffffff);
+	if (!mevt->setup_once)
+		mevt->setup_once = true;
 
 	return 0;
 }
@@ -484,12 +490,10 @@ static int exynos4_local_timer_setup(struct clock_event_device *evt)
 static void exynos4_local_timer_stop(struct clock_event_device *evt)
 {
 	evt->set_mode(CLOCK_EVT_MODE_UNUSED, evt);
-	if (mct_int_type == MCT_INT_SPI) {
-		if (evt->irq != -1)
-			disable_irq_nosync(evt->irq);
-	} else {
+	if (mct_int_type == MCT_INT_SPI)
+		disable_irq(evt->irq);
+	else
 		disable_percpu_irq(mct_irqs[MCT_L0_IRQ]);
-	}
 }
 
 static int exynos4_mct_cpu_notify(struct notifier_block *self,
@@ -521,7 +525,7 @@ static struct notifier_block exynos4_mct_cpu_nb = {
 
 static void __init exynos4_timer_resources(struct device_node *np, void __iomem *base)
 {
-	int err, cpu;
+	int err;
 	struct mct_clock_event_device *mevt = this_cpu_ptr(&percpu_mct_tick);
 	struct clk *mct_clk, *tick_clk;
 
@@ -548,25 +552,7 @@ static void __init exynos4_timer_resources(struct device_node *np, void __iomem
 		WARN(err, "MCT: can't request IRQ %d (%d)\n",
 		     mct_irqs[MCT_L0_IRQ], err);
 	} else {
-		for_each_possible_cpu(cpu) {
-			int mct_irq = mct_irqs[MCT_L0_IRQ + cpu];
-			struct mct_clock_event_device *pcpu_mevt =
-				per_cpu_ptr(&percpu_mct_tick, cpu);
-
-			pcpu_mevt->evt.irq = -1;
-
-			irq_set_status_flags(mct_irq, IRQ_NOAUTOEN);
-			if (request_irq(mct_irq,
-					exynos4_mct_tick_isr,
-					IRQF_TIMER | IRQF_NOBALANCING,
-					pcpu_mevt->name, pcpu_mevt)) {
-				pr_err("exynos-mct: cannot register IRQ (cpu%d)\n",
-									cpu);
-
-				continue;
-			}
-			pcpu_mevt->evt.irq = mct_irq;
-		}
+		irq_set_affinity(mct_irqs[MCT_L0_IRQ], cpumask_of(0));
 	}
 
 	err = register_cpu_notifier(&exynos4_mct_cpu_nb);
@@ -618,8 +604,11 @@ static void __init mct_init_dt(struct device_node *np, unsigned int int_type)
 	exynos4_timer_resources(np, of_iomap(np, 0));
 	exynos4_clocksource_init();
 	exynos4_clockevent_init();
-}
 
+#ifdef CONFIG_SEC_BOOTSTAT
+	sec_bootstat_mct_start(exynos4_read_count_64());
+#endif
+}
 
 static void __init mct_init_spi(struct device_node *np)
 {
